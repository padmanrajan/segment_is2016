\documentclass[a4paper]{article}

\usepackage{INTERSPEECH2016}

\usepackage{graphicx}
\usepackage{amssymb,amsmath,bm}
\usepackage{textcomp}
\usepackage{verbatim}
\def\vec#1{\ensuremath{\bm{{#1}}}}
\def\mat#1{\vec{#1}}


\sloppy % better line breaks
\ninept

\title{Entropy-based segmentation of birdcalls using Fourier transform phase}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If multiple authors, uncomment and edit the lines shown below.       %%
%% Note that each line must be emphasized {\em } by itself.             %%
%% (by Stephen Martucci, author of spconf.sty).                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\makeatletter
%\def\name#1{\gdef\@name{#1\\}}
%\makeatother
%\name{{\em Firstname1 Lastname1, Firstname2 Lastname2, Firstname3 Lastname3,}\\
%      {\em Firstname4 Lastname4, Firstname5 Lastname5, Firstname6 Lastname6,
%      Firstname7 Lastname7}}
%%%%%%%%%%%%%%% End of required multiple authors changes %%%%%%%%%%%%%%%%%

\makeatletter
\def\name#1{\gdef\@name{#1\\}}
\makeatother \name{{\em Author Name$^1$, Co-author Name$^2$}}

\address{$^1$Author Affiliation \\
  $^2$Co-author Affiliation \\
  {\small \tt author@university.edu, coauthor@company.com}
}

%\twoauthors{Karen Sp\"{a}rck Jones.}{Department of Speech and Hearing \\
%  Brittania University, Ambridge, Voiceland \\
%  {\small \tt Karen@sh.brittania.edu} }
%  {Rose Tyler}{Department of Linguistics \\
%  University of Speechcity, Speechland \\
%  {\small \tt RTyler@ling.speech.edu} }

%
\begin{document}

  \maketitle
  %
  \begin{abstract}
  In this paper we describe an entropy-based algorithm for the segmentation of
  birdcalls from recordings. The entropy of time-frequency blocks are estimated
  from the phase of the Fourier transform. To overcome difficulties in
  processing the phase, the group delay function from an all-pole filter is
  utilised. The group delay function has good frequency resolution properties,
  and hence provides relaiable estimates of the entropy. Furthermore, spectral
  whitening is performed to smooth the entropy estimate and the extremities are
  determined. A threshold is applied on the difference to distinguish the call
  periods from the background.  The algorithm is evaluated on two different
  datasets, one of which is recorded in more challenging field conditions. When
  compared to entropy estimated from the power spectrum, the entropy from the
  group delay function provides better detection accuracy at almost all
  operating points. The choice of model order of the all-pole filter for
  different bird species is also briefly investigated.
  \end{abstract}
  \noindent{\bf Index Terms}: bioacoustics, birdcall segmentation, Fourier transform phase
  



\section{Introduction}

With the advent of automated recording devices, the collection of large amounts of
bioacoustic data has become relatively easy. By analysing birdcalls collected in
this manner, it is possible to perform tasks such as the tracking of migrant
species or examining the avian biodiversity of a given region. Typically, the
collected data is processed offline. In this process, the first step is usually to
determine regions of interest in the recording. An entropy-based bird phrase segmentation
technique was developed in \cite{wang2013}. In this paper, we propose a modified
version of that technique, by using information from the phase of the short-term
Fourier transform (STFT.) Most techniques for processing speech and audio signals have
utilised the magnitude spectrum of the STFT. Although the phase spectrum of the STFT has 
useful information, its processing has remained difficult. A popular technique
for exploiting information from the phase has been through group delay functions. In
this work, we utilise information from group delay functions using parametric
models, and apply it to segment birdcalls into active and inactive regions.

The group delay function has good frequency resolution propreties, which enable
it to be useful in tasks such as speech recognition and speaker recognition
\cite{hema,padman}. The same property is beneficial in the processing of bird
vocalizations. In \cite{wang2013}, the entropy within a sliding time-frequency
window over the spectrogram has been effectively used for distinguishing active
and inactive regions. The essential idea is that birdcalls have more structure
(for eg.~harmonics may be present), and thus have lower entropy when compared to
 background sounds, which have higher entropy. This difference in entropy
levels enable effective distinction between birdcalls and the background.
%Applying a similar technique with the group delay function, rather than the
%spectrogram, provides increased frequency resolution, and hence more effective
%entropy computation. 
The high resolution property of group delay functions enable accurate tracking
of time-frequency information. In this work, the entropy of a sliding
time-frequency window is estimated from the group delay representation. Spectral
whitening is applied to smooth the entropy estimates and simple thresholding is
applied to separate the birdcalls from the background.

Other methods for segmentation of birdsong include

\section{Utilising Fourier transform phase}

Commonly used features for processing speech and audio signals are based on the
magnitude spectrum of the short-term Fourier transform. The phase spectrum has
received relatively lesser attention due to signal processing difficulties, one
of them being the need to unwrap the phase spectrum. The unwrapping problem can be
bypassed by utilising the group delay function, which is the negative derivative
of the phase spectrum. The group delay function can be
computed using properties of the Fourier transform, and hence avoids the need
for explicit computation of the phase spectrum \cite{gdDeriv}. 
However, this method can produce
artifacts in the form of spurious peaks at spectral nulls. These nulls
correspond to zeros close to the unit circle when the vocal tract transfer
function is represented in the $Z$ domain. 
%To avoid these spurious peaks, a
%minimum-phase assumption is made on the 
%underlying system. 
Several methods have been proposed in the literature to overcome the effects due
to these artifacts \cite{modgdf, productSpectrum}. Another technique to overcome
this difficulty is to model the vocal tract as an all-pole filter, hence
avoiding the nulls altogether. Such a
technique derived using linear prediction analysis was used in the detection of
formants in human speech \cite{yegnaFormant}. 


There is strong evidence that birds use their vocal tract as a selective filter
to modify the final sound \cite{catchpole}.  Given this, the source-filter model
developed for analysing human speech can be applied to bird vocalizations as
well.  Linear predictive (LP) analysis of human speech signals models the vocal
tract spectrum as an all-pole filter \cite{makhoul} excited by a single source.
When applied to birdcalls, this is a simplification of the `two-voice' theory of
avian vocalization\cite{catchpoole}, in that there is assumed to be only one
source, rather than two. Nevertheless, this reasonable assumption is followed in
this work. A similar assumption has been made in \cite{agnihotri}, where LP
analysis has been applied in analysing the song of the greater racket-tailed
drongo.

The vocal tract is represented in the LP model as
\begin{equation}
H(\omega) = \frac{G}{1-\sum_{k=1}^{P} a(k) e^{-j \omega k}},
\end{equation}
where the predictor model order is $P$, $G$ represents the gain and $a(k)$ are
the predictor coefficientses\cite{makhoul}.
The filter reprsented by $H(\omega)$ is an all-pole filter, and its group delay
function does not suffer from the artifacts mentioned earlier. The group delay
function computed in this manner is termed as all-pole group delay
function (APGDF.) Figure \ref{fig:apgd} shows the magnitude spectrum, LP
spectrum and APGDF derived from a 20 ms call of Cassins vireo (\textit{Vireo
cassinii.}) As can be seen, the APGDF emphasises the formants, as compared to the
DFT magnitude spectrum or the LP magnitude spectrum. Two peaks which are merged
in the magnitude spectra around the 100th frequency bin appear distinctly in the
APGDF.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth,height=7cm]{apGd.eps}
\caption{based on all pole model (in the bottom panel).}
\label{fig:all-pole}
\end{figure}


Recently, feature vectors
derived from such a representation was used in speech \cite{drugman} and speaker
recognition \cite{padman}. 



%This is equivalent to a cascade of several
%first-order and second-order all-pole filters. The overall magnitude spectrum is
%the product of the individual magnitude spectra, and the overall phase spectrum
%is the sum of the individual phase spectra \cite{yegnaFormant}. Although
%developed for human speech, th






\section{Entropy-based segmentation of birdsong}

After dividing the input recording into frames, APGDF is estimated for each
frame. A sliding time-frequency window of width $w$ frames and frequency range
$fmin$ to $fmax$ is considered over the APGDF vectors. As in \cite{wang2013},
the entropy of this window is estimated using the expression
\begin{equation}
H(\omega) = \frac{G}{1-\sum_{k=1}^{P} a(k) e^{-j \omega k}},
\end{equation}

Unlike the power spectrum, the APGDF can be negative. 
Since here we are interested only in the magnitudes and
locations of the frequency components, the sign of the APGDF is
ignored by taking the absolute value. 
%The APGDF from figure
%\ref{fig:apgd} is shown in \ref{fig:apgdNoSign} after ignoring the sign.
%\begin{figure}[h]
%\centering
%\includegraphics[width=0.5\textwidth,height=2cm]{apgdNoSign.eps}
%\caption{based on all pole model (in the bottom panel).}
%\label{fig:all-pole}
%\end{figure}







This section describes how to calculate entropy from spectrogram and phase
spectrum, also how to use entropy to identify bird vocalizations. In
\cite{wang2013}, the entropy of spectrograms from recordings can be effectively used for distinguishing
between background and bird vocalizations \cite{6625329}. Spectrogram of single
bird song is generally sparse i.e. high power components acquire only a small
portion of time-frequency bins and the background noise of spectrogram is
relatively white. Hence  the entropy of sliding time frequency block over
spectrogram is low when block contains a signal and is high when only background
is present in that block. It is known that phase spectrum has more information
than magnitude spectrum. So, phase spectrum can also be used to calculate
entropy. Group delay functions from all pole models are used to calculate the
phase spectrum. 

\subsection{Entropy Calculation}
Entropy is calculated for each time-frequency block on power spectrum. This time-frequency block of time length \textbf{\textit{w}} and having F frequency bins ranging from \textbf{\textit{f1}} to  \textbf{\textit{fn}} is moved horizontally from beginning to the end of power spectrum. The frequency range is different for each target species. \textbf{\textit{p(n,f)}} is power spectrum at time \textbf{\textit{n}} and frequency  \textbf{\textit{f}}. The entropy is calculated using following equation:

\hspace{1cm}

  $h_{k}=\sum_{n=kT+1}^{kT+w}\sum_{f=f1}^{fn}z(n,f) \ln z(n,f)$

 \hspace{1cm}
 
Here \textbf{\textit{T}} is time-frequency block shift and \textbf{\textit{z(n,f)}} is normalized power spectrum.


\hspace{1cm}

$z(n,f)=\frac {p(n,f)}
{\sum_{n=kT+1}^{kT+w}\sum_{f=f1}^{fn} p(n,f)}$

\hspace{1cm}


The entropy calculated from block is less susceptible to the bursts of background noise in comparison to the entropy calculated at each time instance. 


\subsection{Whitening Spectrogram before Entropy Calculation}

To identify the bird vocalizations using entropy, there should be a clear distinction between the entropy of background and call period. However this is not always the case in raw sound recordings. Depending on the interference level, entropy at a quiet period can even be higher than the entropy at a call period or bird call activity [1]. To overcome this problem, whole spectrogram or power spectrum is whitened using PCA  before calculating entropy. The entropy calculated from whitened spectrogram is almost constant for background but dips enough to mark the presence of bird vocalizations. Even low energy bird vocalizations can be detected accurately using this method. The missed detection rate is decreased if whitened spectrogram is used for entropy calculation. 

To whiten the spectrogram (\textit{PS}), the covariance matrix of mean subtracted spectrogram is calculated. The Eigen values matrix (\textit{S}) and Eigen vectors matrix (\textit{U}) of this covariance matrix are calculated. The spectrogram matrix is whitened using the following equation:

\hspace{1cm}

$WhitePS=diag(\frac{1}{\sqrt{diag(S)+\epsilon}})*\textit{U'}*\textit{PS}$


\hspace{1cm}


Figure 1 depicts the difference between entropy calculated from normal spectrogram and whitened spectrogram:
\begin{figure}[!ht]
	\centering
	\includegraphics[width=8cm, height=6cm]{entropy}
	\caption{ Entropy calculated from normal spectrogram and whitened spectrogram}   
\end{figure}

It becomes evident that identifying bird vocalizations using entropy calculated from whitened spectrogram is easier.  



\subsection{Entropy Calculation from phase spectrum}



\subsection{Detecting change points using thresholding}

To detect the change points, thresholding is used. The local minimums and local maximums are calculated on the  entropy. The difference between consecutive local minimums and local maximums is calculated. If this difference is greater than pre-defined threshold, then corresponding local maximum is considered as the start of a bird vocalization or a change point. Then the difference between corresponding local minima and next local maxima is calculated. If this difference is greater than the threshold, local maxima is considered as the end of bird vocalization or another change point. Hence two contiguous change points correspond to the start and end of a bird vocalization. These change points can be tracked back to get the start and end time of the vocalization in sound recording. Figure 2 shows the local maximums and local minimums on an entropy plot along with change points calculated from thresholding.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=9cm, height=4cm]{thresholding}
	\caption{ Change points generated by thresholding and Extrema calculated on entropy}   
\end{figure} 

   




\section{Experimentation and Performance Analysis}

For experimentation, the labeled recordings of Cassin’s Vireo (\textit{Vireo cassinii}) and single species MLSP Bird Classification Challaenge 2013 datasets are used \cite{data}. 

In Cassin's Vireo dataset, the total duration of recordings is about 45 minutes. Out of 45 minutes, about 5 minutes of recordings correspond to the phrases of Cassin's Vireo. To calculate spectrogram, frame length of 20 ms and increment of  
5 ms is used. The time-frequency window of 138.8 ms is used along with increment of 15 ms to calculate entropy. The frequency range of the block is from 1.5 kHz to 7 kHz.  

The method is analyzed using manual annotations of bird vocalizations. For performance analysis, three metrics i.e. true positive rate, missed detection rate and false alarm rate are used. These metrics are calculated using following equations:\newline



$\text{True Positive rate (\%)}=\frac{\text{Frames correctly classified as calls}} {\text{Total frames contating call activity}} \times 100$\newline


$\text{Missed Detection (\%)}=\frac{\text{Frames  misclassified as background}} {\text{Total call activity frames}} \times 100$\newline

$\text{False Alarms (\%)}=\frac{\text{Background  frames classified as calls}} {\text{Total background frames}} \times 100$ \newline



 ROC curves are used for analyzing the method. Figure 3 depicts ROC curves comparing performance of methods based on entropy calculated from whitened spectrogram and entropy calculated from whitened group delay phase spectrum. It is clear from ROC plot in Figure 3 that whitened Group delay phase spectrum method is outperforming whitened power spectrum method.


\begin{figure}[!ht]
	\centering
	\includegraphics[width=9cm, height=5cm]{Power_vs_phase_white}
	\caption{ROC curves comparing white phase spectrum and white power spectrum methods}   
\end{figure} 



The effect of whitening the phase spectrum before entropy calculation is evident from the ROC curves depicted in Figure 4 and Figure 5. The analysis of ROC in Figure 4 establishes that whitening the phase spectrum gives better performance than using phase spectrum which is not whitened. 

\begin{figure}[!ht]
	\centering
	\includegraphics[width=9cm, height=5cm]{phase_non_white_vs_phase_white}
	\caption{ROC curves comparing performance of methods based whitened phase spectrum and non white phase spectrum}   
\end{figure} 
 
 Figure 5 shows comparison of ROC plots between methods based on white and non white power spectrum. 
 
 \begin{figure}[!ht]
 	\centering
 	\includegraphics[width=9cm, height=5cm]{phase_non_white_vs_phase_white}
 	\caption{ROC curves comparing performance of methods based whitened power spectrum and non white power spectrum}   
 \end{figure} 
 
 
 
 
The method is also evaluated on an another dataset i.e. single species MLSP Bird Classification Challaenge 2013. The recordings have low signal to noise ratio.  Figure 6 shows ROC curves comparing performance of methods based on entropy calculated from whitened spectrogram and entropy calculated from whitened group delay phase spectrum on single species MLSP data.

 
\begin{figure}[!ht]
	\centering
	\includegraphics[width=9cm, height=4cm]{ROC_data_2_gd_vs_spectogram_white}
	\caption{ROC curves comparing performance of methods based on white phase spectrum and white power spectrum on MLSP 2013 single species dataset }   
\end{figure} 

 



%%  write formullae for calculating correct, missed detection and false alarms
\begin{comment}
Table 1 shows results generated by applying entropy based segmentation with thresholding on different sound recordings. 

  



\begin{table}[]
	\centering
	\caption{Table showing Correct (\%) Missed Detection(\%) and False alarm (\%) for particular thresholds and moving average windows } 
	\label{Table 1}

	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\textbf{File} & \textbf{Span} & \textbf{Threshold} & \textbf{Correct (\%)} & \textbf{False Alarm (\%)} & \textbf{Missed Detection (\%)} \\ \hline
		1.wav         & 9             & 1.2                & 77.7                  & 15.6                      & 60.5                           \\
	\hline	2.wav         & 3             & 1.45               & 73                    & 45                        & 25                             \\
		\hline	3.wav         & 3             & 1.5                & 71                    & 22                        & 54                             \\
		\hline	4.wav         & 9             & 1.15               & 75.1              & 21                  & 51.5                       \\
		\hline	5.wav         & 7             & 1.5                & 76.5                  & 18.5                      & 45                             \\
	\hline		6.wav         & 9             & 1.25               & 82.1              & 15.07                  & 32.2                       \\
		\hline	7.wav         & 7             & 1.25               & 79.6              & 17.8                  & 46.7                       \\
		\hline	8.wav         & 9             & 1.15               & 78.8              & 19.3                  & 35.1                      \\
		\hline	9.wav         & 5             & 1.5                & 86.06              & 13.6                  & 17.9                       \\
	\hline		10.wav        & 9             & 1.6                & 79.6              & 18.3                  & 28.31                       \\
		\hline	11.wav        & 3             & 1.45               & 91.1                  & 32.7                      & 7.53                           \\
		\hline	12.wav        & 7             & 1.4                & 85.1              & 11.3                   & 38.1      \\ \hline               	
	 
	\end{tabular}

\end{table}

\end{comment}
 
 
\section{Conclusion}
We propose an entropy based bird vocalization segmentation method where entropy is calculated from Group Delay phase spectrum. It is also established that whitening the power or phase spectrum before entropy calculation improves the performance of entropy based segmentation. From experimentation,it is clear that the proposed group delay based method outperforms the power spectrum based method.  



  \newpage
  \eightpt
  \bibliographystyle{IEEEtran}

  \bibliography{mybib}

%  \begin{thebibliography}{9}
%    \bibitem[1]{Davis80-COP}
%      S.\ B.\ Davis and P.\ Mermelstein,
%      ``Comparison of parametric representation for monosyllabic word recognition in continuously spoken sentences,''
%      \textit{IEEE Transactions on Acoustics, Speech and Signal Processing}, vol.~28, no.~4, pp.~357--366, 1980.
%    \bibitem[2]{Rabiner89-ATO}
%      L.\ R.\ Rabiner,
%      ``A tutorial on hidden Markov models and selected applications in speech recognition,''
%      \textit{Proceedings of the IEEE}, vol.~77, no.~2, pp.~257-286, 1989.
%    \bibitem[3]{Hastie09-TEO}
%      T.\ Hastie, R.\ Tibshirani, and J.\ Friedman,
%      \textit{The Elements of Statistical Learning -- Data Mining, Inference, and Prediction}.
%      New York: Springer, 2009.
%    \bibitem[4]{YourName16-XXX}
%      F.\ Lastname1, F.\ Lastname2, and F.\ Lastname3,
%      ``Title of your INTERSPEECH 2016 publication,''
%      in \textit{Interspeech 2016 -- 16\textsuperscript{th} Annual Conference of the International Speech Communication Association, September 8–12, San Francisco, California, USA, Proceedings, Proceedings}, 2016, pp.~100--104.
%  \end{thebibliography}

\end{document}
